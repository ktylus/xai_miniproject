{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from early_stopping import EarlyStopping\n",
    "\n",
    "from datasets import CaliforniaHousingDataset, AdultDataset, TitanicDataset, AutoMpgDataset, WineDataset\n",
    "from metrics import calculate_global_fidelity, calculate_global_neighborhood_fidelity\n",
    "from models.base_model import BaseClassifier, BaseRegressor\n",
    "from models.surrogate_model import SurrogateClassifier, SurrogateRegressor\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "housing_train = CaliforniaHousingDataset(\n",
    "    dataset_path=\"data/california_housing/cal_housing.data\", normalize=True, train=True)\n",
    "housing_test = CaliforniaHousingDataset(\n",
    "    dataset_path=\"data/california_housing/cal_housing.data\", normalize=True, train=False)\n",
    "\n",
    "adult_train = AdultDataset(dataset_path=\"data/adult/adult.data\", normalize=True, train=True)\n",
    "adult_test = AdultDataset(dataset_path=\"data/adult/adult.data\", normalize=True, train=False)\n",
    "\n",
    "titanic_train = TitanicDataset(dataset_path=\"data/titanic/titanic.arff\", normalize=True, train=True)\n",
    "titanic_test = TitanicDataset(dataset_path=\"data/titanic/titanic.arff\", normalize=True, train=False)\n",
    "\n",
    "wine_train = WineDataset(dataset_path=\"data/wines/winequality-red.csv\", normalize=True, train=True)\n",
    "wine_test = WineDataset(dataset_path=\"data/wines/winequality-red.csv\", normalize=True, train=False)\n",
    "\n",
    "autompg_train = AutoMpgDataset(dataset_path=\"data/autompg/auto-mpg.data\", normalize=True, train=True)\n",
    "autompg_test = AutoMpgDataset(dataset_path=\"data/autompg/auto-mpg.data\", normalize=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# target normalization just to check (the mse scores in the paper are low - what's the transformation / metric used?)\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# after seeing the results, it seems the authors just put the target through a StandardScaler\n",
    "# housing_train.target = pd.Series(scaler.fit_transform(np.array(housing_train.target).reshape(-1, 1)).flatten())\n",
    "# housing_test.target = pd.Series(scaler.fit_transform(np.array(housing_test.target).reshape(-1, 1)).flatten())\n",
    "# wine_train.target = pd.Series(scaler.fit_transform(np.array(wine_train.target).reshape(-1, 1)).flatten())\n",
    "# wine_test.target = pd.Series(scaler.fit_transform(np.array(wine_test.target).reshape(-1, 1)).flatten())\n",
    "# autompg_train.target = pd.Series(scaler.fit_transform(np.array(autompg_train.target).reshape(-1, 1)).flatten())\n",
    "# autompg_test.target = pd.Series(scaler.fit_transform(np.array(autompg_test.target).reshape(-1, 1)).flatten())\n",
    "\n",
    "# TODO move that to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 128  # not from the paper\n",
    "binary_classification_criterion = torch.nn.BCELoss()\n",
    "regression_criterion = ... # \"logarithm of the hyperbolic cosine\" from the paper (?)\n",
    "regression_criterion = torch.nn.MSELoss()\n",
    "# TODO early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "        base_model: nn.Module,\n",
    "        surrogate_model: nn.Module,\n",
    "        train_data: Dataset,\n",
    "        criterion,\n",
    "        epochs: int,\n",
    "        alpha: float,\n",
    "        early_stopping: EarlyStopping = None\n",
    "):\n",
    "    params = list(base_model.parameters()) + list(surrogate_model.parameters())\n",
    "    optimizer = Adam(params, lr=lr)\n",
    "    loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for data, labels in loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            labels = labels.reshape(-1, 1)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            base_model_preds = base_model(data)\n",
    "            surrogate_model_preds = surrogate_model(data)\n",
    "            loss = criterion(base_model_preds, labels)\n",
    "            point_fidelity = calculate_global_fidelity(base_model_preds, surrogate_model_preds)\n",
    "            mtl_loss = alpha * loss + (1 - alpha) * point_fidelity\n",
    "        \n",
    "            mtl_loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += mtl_loss\n",
    "        \n",
    "        train_loss = running_loss / len(loader)\n",
    "        if early_stopping is not None:\n",
    "            early_stopping(train_loss, base_model, surrogate_model)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "        print(f\"epoch: {epoch + 1}, train loss: {train_loss:.3f}\")\n",
    "\n",
    "\n",
    "def validate_base_classifier(\n",
    "        model: nn.Module,\n",
    "        test_data: Dataset,\n",
    "):\n",
    "    loader = DataLoader(test_data, batch_size=len(test_data))\n",
    "    with torch.no_grad():\n",
    "        data, labels = next(iter(loader))\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        labels = labels.reshape(-1, 1)\n",
    "        preds_proba = model(data)\n",
    "        preds = torch.where(preds_proba >= 0.5, 1, 0)\n",
    "        accuracy = sklearn.metrics.accuracy_score(labels.cpu(), preds.cpu())\n",
    "        f1_score = sklearn.metrics.f1_score(labels.cpu(), preds.cpu())\n",
    "        print(f\"test accuracy: {accuracy:.3f}, f1 score: {f1_score:.3f}\")\n",
    "\n",
    "\n",
    "def validate_base_regressor(\n",
    "        model: nn.Module,\n",
    "        test_data: Dataset\n",
    "):\n",
    "    loader = DataLoader(test_data, batch_size=len(test_data))\n",
    "    with torch.no_grad():\n",
    "        data, labels = next(iter(loader))\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        labels = labels.reshape(-1, 1)\n",
    "        preds = model(data)\n",
    "        mse = sklearn.metrics.mean_squared_error(labels.cpu(), preds.cpu())\n",
    "        print(f\"test mse: {mse:.3f}\")\n",
    "\n",
    "\n",
    "def validate_surrogate_model(\n",
    "        base_model: nn.Module,\n",
    "        surrogate_model: nn.Module,\n",
    "        test_data: Dataset\n",
    "):\n",
    "    loader = DataLoader(test_data, batch_size=len(test_data))\n",
    "    with torch.no_grad():\n",
    "        data, _ = next(iter(loader))\n",
    "        data = data.to(device)\n",
    "        base_model_preds = base_model(data)\n",
    "        surrogate_model_preds = surrogate_model(data)\n",
    "        global_fidelity = calculate_global_fidelity(base_model_preds, surrogate_model_preds)\n",
    "        global_neighborhood_fidelity = calculate_global_neighborhood_fidelity(base_model, surrogate_model, data)\n",
    "        print(f\"global fidelity: {global_fidelity:.3f}, global neighborhood fidelity: {global_neighborhood_fidelity:.3f}\")\n",
    "\n",
    "\n",
    "def validate_regressors(\n",
    "        base_model: nn.Module,\n",
    "        surrogate_model: nn.Module,\n",
    "        test_data: Dataset\n",
    "):\n",
    "    validate_base_regressor(base_model, test_data)\n",
    "    validate_surrogate_model(base_model, surrogate_model, test_data)\n",
    "\n",
    "\n",
    "def validate_classifiers(\n",
    "        base_model: nn.Module,\n",
    "        surrogate_model: nn.Module,\n",
    "        test_data: Dataset\n",
    "):\n",
    "    validate_base_classifier(base_model, test_data)\n",
    "    validate_surrogate_model(base_model, surrogate_model, test_data)\n",
    "\n",
    "# TODO local explainability evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult:\n",
      "Saving models ...\n",
      "epoch: 1, train loss: 0.216\n",
      "Saving models ...\n",
      "epoch: 2, train loss: 0.178\n",
      "Saving models ...\n",
      "epoch: 3, train loss: 0.169\n",
      "Saving models ...\n",
      "epoch: 4, train loss: 0.163\n",
      "Saving models ...\n",
      "epoch: 5, train loss: 0.159\n",
      "Saving models ...\n",
      "epoch: 6, train loss: 0.156\n",
      "Saving models ...\n",
      "epoch: 7, train loss: 0.154\n",
      "Saving models ...\n",
      "epoch: 8, train loss: 0.151\n",
      "Saving models ...\n",
      "epoch: 9, train loss: 0.150\n",
      "Saving models ...\n",
      "epoch: 10, train loss: 0.148\n",
      "Saving models ...\n",
      "epoch: 11, train loss: 0.147\n",
      "Saving models ...\n",
      "epoch: 12, train loss: 0.145\n",
      "Saving models ...\n",
      "epoch: 13, train loss: 0.144\n",
      "Saving models ...\n",
      "epoch: 14, train loss: 0.142\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 15, train loss: 0.143\n",
      "Saving models ...\n",
      "epoch: 16, train loss: 0.140\n",
      "Saving models ...\n",
      "epoch: 17, train loss: 0.139\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 18, train loss: 0.141\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 19, train loss: 0.139\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 20, train loss: 0.152\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 21, train loss: 0.141\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 22, train loss: 0.141\n",
      "Saving models ...\n",
      "epoch: 23, train loss: 0.131\n",
      "Saving models ...\n",
      "epoch: 24, train loss: 0.129\n",
      "Saving models ...\n",
      "epoch: 25, train loss: 0.128\n",
      "Saving models ...\n",
      "epoch: 26, train loss: 0.127\n",
      "Saving models ...\n",
      "epoch: 27, train loss: 0.126\n",
      "Saving models ...\n",
      "epoch: 28, train loss: 0.124\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 29, train loss: 0.126\n",
      "Saving models ...\n",
      "epoch: 30, train loss: 0.123\n",
      "Saving models ...\n",
      "epoch: 31, train loss: 0.122\n",
      "Saving models ...\n",
      "epoch: 32, train loss: 0.119\n",
      "Saving models ...\n",
      "epoch: 33, train loss: 0.118\n",
      "Saving models ...\n",
      "epoch: 34, train loss: 0.118\n",
      "Saving models ...\n",
      "epoch: 35, train loss: 0.116\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 36, train loss: 0.118\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 37, train loss: 0.116\n",
      "Saving models ...\n",
      "epoch: 38, train loss: 0.114\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 39, train loss: 0.116\n",
      "Saving models ...\n",
      "epoch: 40, train loss: 0.113\n",
      "Saving models ...\n",
      "epoch: 41, train loss: 0.110\n",
      "Saving models ...\n",
      "epoch: 42, train loss: 0.108\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 43, train loss: 0.110\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 44, train loss: 0.109\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 45, train loss: 0.111\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 46, train loss: 0.110\n",
      "Saving models ...\n",
      "epoch: 47, train loss: 0.108\n",
      "Saving models ...\n",
      "epoch: 48, train loss: 0.106\n",
      "Saving models ...\n",
      "epoch: 49, train loss: 0.106\n",
      "Saving models ...\n",
      "epoch: 50, train loss: 0.104\n",
      "Saving models ...\n",
      "epoch: 51, train loss: 0.104\n",
      "Saving models ...\n",
      "epoch: 52, train loss: 0.102\n",
      "Saving models ...\n",
      "epoch: 53, train loss: 0.101\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 54, train loss: 0.103\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 55, train loss: 0.102\n",
      "Saving models ...\n",
      "epoch: 56, train loss: 0.100\n",
      "Saving models ...\n",
      "epoch: 57, train loss: 0.099\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 58, train loss: 0.105\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 59, train loss: 0.100\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 60, train loss: 0.102\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 61, train loss: 0.100\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 62, train loss: 0.099\n",
      "EarlyStopping counter: 6 out of 10\n",
      "epoch: 63, train loss: 0.099\n",
      "Saving models ...\n",
      "epoch: 64, train loss: 0.097\n",
      "Saving models ...\n",
      "epoch: 65, train loss: 0.094\n",
      "Saving models ...\n",
      "epoch: 66, train loss: 0.092\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 67, train loss: 0.092\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 68, train loss: 0.095\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 69, train loss: 0.096\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 70, train loss: 0.096\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 71, train loss: 0.098\n",
      "EarlyStopping counter: 6 out of 10\n",
      "epoch: 72, train loss: 0.097\n",
      "Saving models ...\n",
      "epoch: 73, train loss: 0.091\n",
      "Saving models ...\n",
      "epoch: 74, train loss: 0.090\n",
      "Saving models ...\n",
      "epoch: 75, train loss: 0.089\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 76, train loss: 0.091\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 77, train loss: 0.092\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 78, train loss: 0.091\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 79, train loss: 0.091\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 80, train loss: 0.093\n",
      "EarlyStopping counter: 6 out of 10\n",
      "epoch: 81, train loss: 0.095\n",
      "EarlyStopping counter: 7 out of 10\n",
      "epoch: 82, train loss: 0.092\n",
      "Saving models ...\n",
      "epoch: 83, train loss: 0.089\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 84, train loss: 0.090\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 85, train loss: 0.090\n",
      "Saving models ...\n",
      "epoch: 86, train loss: 0.088\n",
      "Saving models ...\n",
      "epoch: 87, train loss: 0.088\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 88, train loss: 0.093\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 89, train loss: 0.093\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 90, train loss: 0.090\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 91, train loss: 0.088\n",
      "Saving models ...\n",
      "epoch: 92, train loss: 0.086\n",
      "Saving models ...\n",
      "epoch: 93, train loss: 0.085\n",
      "Saving models ...\n",
      "epoch: 94, train loss: 0.083\n",
      "Saving models ...\n",
      "epoch: 95, train loss: 0.083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 96, train loss: 0.086\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 97, train loss: 0.087\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 98, train loss: 0.091\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 99, train loss: 0.091\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 100, train loss: 0.089\n",
      "\n",
      "titanic:\n",
      "Saving models ...\n",
      "epoch: 1, train loss: 0.406\n",
      "Saving models ...\n",
      "epoch: 2, train loss: 0.385\n",
      "Saving models ...\n",
      "epoch: 3, train loss: 0.377\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 4, train loss: 0.378\n",
      "Saving models ...\n",
      "epoch: 5, train loss: 0.376\n",
      "Saving models ...\n",
      "epoch: 6, train loss: 0.373\n",
      "Saving models ...\n",
      "epoch: 7, train loss: 0.370\n",
      "Saving models ...\n",
      "epoch: 8, train loss: 0.366\n",
      "Saving models ...\n",
      "epoch: 9, train loss: 0.361\n",
      "Saving models ...\n",
      "epoch: 10, train loss: 0.355\n",
      "Saving models ...\n",
      "epoch: 11, train loss: 0.347\n",
      "Saving models ...\n",
      "epoch: 12, train loss: 0.338\n",
      "Saving models ...\n",
      "epoch: 13, train loss: 0.333\n",
      "Saving models ...\n",
      "epoch: 14, train loss: 0.319\n",
      "Saving models ...\n",
      "epoch: 15, train loss: 0.315\n",
      "Saving models ...\n",
      "epoch: 16, train loss: 0.310\n",
      "Saving models ...\n",
      "epoch: 17, train loss: 0.297\n",
      "Saving models ...\n",
      "epoch: 18, train loss: 0.295\n",
      "Saving models ...\n",
      "epoch: 19, train loss: 0.287\n",
      "Saving models ...\n",
      "epoch: 20, train loss: 0.277\n",
      "Saving models ...\n",
      "epoch: 21, train loss: 0.256\n",
      "Saving models ...\n",
      "epoch: 22, train loss: 0.247\n",
      "Saving models ...\n",
      "epoch: 23, train loss: 0.246\n",
      "Saving models ...\n",
      "epoch: 24, train loss: 0.240\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 25, train loss: 0.241\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 26, train loss: 0.241\n",
      "Saving models ...\n",
      "epoch: 27, train loss: 0.240\n",
      "Saving models ...\n",
      "epoch: 28, train loss: 0.235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 29, train loss: 0.236\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 30, train loss: 0.238\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 31, train loss: 0.239\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 32, train loss: 0.236\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 33, train loss: 0.237\n",
      "Saving models ...\n",
      "epoch: 34, train loss: 0.232\n",
      "Saving models ...\n",
      "epoch: 35, train loss: 0.229\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 36, train loss: 0.232\n",
      "Saving models ...\n",
      "epoch: 37, train loss: 0.228\n",
      "Saving models ...\n",
      "epoch: 38, train loss: 0.228\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 39, train loss: 0.228\n",
      "Saving models ...\n",
      "epoch: 40, train loss: 0.227\n",
      "Saving models ...\n",
      "epoch: 41, train loss: 0.226\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 42, train loss: 0.226\n",
      "Saving models ...\n",
      "epoch: 43, train loss: 0.226\n",
      "Saving models ...\n",
      "epoch: 44, train loss: 0.225\n",
      "Saving models ...\n",
      "epoch: 45, train loss: 0.224\n",
      "Saving models ...\n",
      "epoch: 46, train loss: 0.224\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 47, train loss: 0.224\n",
      "Saving models ...\n",
      "epoch: 48, train loss: 0.224\n",
      "Saving models ...\n",
      "epoch: 49, train loss: 0.222\n",
      "Saving models ...\n",
      "epoch: 50, train loss: 0.222\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 51, train loss: 0.222\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 52, train loss: 0.222\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 53, train loss: 0.223\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 54, train loss: 0.222\n",
      "Saving models ...\n",
      "epoch: 55, train loss: 0.221\n",
      "Saving models ...\n",
      "epoch: 56, train loss: 0.219\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 57, train loss: 0.219\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 58, train loss: 0.220\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 59, train loss: 0.223\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 60, train loss: 0.229\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 61, train loss: 0.223\n",
      "EarlyStopping counter: 6 out of 10\n",
      "epoch: 62, train loss: 0.237\n",
      "EarlyStopping counter: 7 out of 10\n",
      "epoch: 63, train loss: 0.224\n",
      "Saving models ...\n",
      "epoch: 64, train loss: 0.218\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 65, train loss: 0.222\n",
      "Saving models ...\n",
      "epoch: 66, train loss: 0.215\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 67, train loss: 0.218\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 68, train loss: 0.217\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 69, train loss: 0.218\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 70, train loss: 0.215\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 71, train loss: 0.215\n",
      "EarlyStopping counter: 6 out of 10\n",
      "epoch: 72, train loss: 0.216\n",
      "Saving models ...\n",
      "epoch: 73, train loss: 0.213\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 74, train loss: 0.213\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 75, train loss: 0.214\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 76, train loss: 0.214\n",
      "Saving models ...\n",
      "epoch: 77, train loss: 0.211\n",
      "Saving models ...\n",
      "epoch: 78, train loss: 0.211\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 79, train loss: 0.213\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 80, train loss: 0.220\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 81, train loss: 0.217\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 82, train loss: 0.239\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 83, train loss: 0.228\n",
      "EarlyStopping counter: 6 out of 10\n",
      "epoch: 84, train loss: 0.219\n",
      "EarlyStopping counter: 7 out of 10\n",
      "epoch: 85, train loss: 0.211\n",
      "Saving models ...\n",
      "epoch: 86, train loss: 0.210\n",
      "Saving models ...\n",
      "epoch: 87, train loss: 0.209\n",
      "Saving models ...\n",
      "epoch: 88, train loss: 0.208\n",
      "Saving models ...\n",
      "epoch: 89, train loss: 0.208\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 90, train loss: 0.208\n",
      "Saving models ...\n",
      "epoch: 91, train loss: 0.205\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 92, train loss: 0.205\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 93, train loss: 0.205\n",
      "Saving models ...\n",
      "epoch: 94, train loss: 0.204\n",
      "Saving models ...\n",
      "epoch: 95, train loss: 0.202\n",
      "Saving models ...\n",
      "epoch: 96, train loss: 0.202\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 97, train loss: 0.207\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 98, train loss: 0.204\n",
      "Saving models ...\n",
      "epoch: 99, train loss: 0.201\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 100, train loss: 0.207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "alpha = 0.5\n",
    "patience = 10 # num of epochs to early stop if loss doesn't decrease\n",
    "save_dir = \"checkpoints\"\n",
    "\n",
    "classification_data = {\n",
    "    \"adult\": (adult_train, adult_test),\n",
    "    \"titanic\": (titanic_train, titanic_test)\n",
    "}\n",
    "classifiers = []\n",
    "\n",
    "for dataset in classification_data.keys():\n",
    "    train_data, test_data = classification_data[dataset]\n",
    "    base_model = BaseClassifier(\n",
    "        input_dim=train_data.features.shape[1], output_dim=1, n_hidden_layers=4, layer_size=128).to(device)\n",
    "    surrogate_model = SurrogateClassifier(input_dim=train_data.features.shape[1], output_dim=1).to(device)\n",
    "    print(f\"{dataset}:\")\n",
    "    early_stopping = EarlyStopping(dir=save_dir, dataset_name=dataset, patience=patience, verbose=False)\n",
    "    train(base_model, surrogate_model, train_data, binary_classification_criterion, epochs, alpha, early_stopping)\n",
    "    classifiers.append((base_model, surrogate_model))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult:\n",
      "test accuracy: 0.921, f1 score: 0.834\n",
      "global fidelity: 0.048, global neighborhood fidelity: 0.050\n",
      "\n",
      "titanic:\n",
      "test accuracy: 0.837, f1 score: 0.770\n",
      "global fidelity: 0.032, global neighborhood fidelity: 0.032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, dataset in enumerate(classification_data.keys()):\n",
    "    test_data = classification_data[dataset][1]\n",
    "    \n",
    "    base_model = BaseClassifier(\n",
    "        input_dim=test_data.features.shape[1], output_dim=1, n_hidden_layers=4, layer_size=128).to(device)\n",
    "    surrogate_model = SurrogateClassifier(input_dim=test_data.features.shape[1], output_dim=1).to(device)\n",
    "    \n",
    "    base_model.load_state_dict(torch.load(f\"{save_dir}/{dataset}/base_model_checkpoint.pt\"))\n",
    "    surrogate_model.load_state_dict(torch.load(f\"{save_dir}/{dataset}/surrogate_model_checkpoint.pt\"))\n",
    "    \n",
    "    base_model.eval()\n",
    "    surrogate_model.eval()\n",
    "    \n",
    "    print(f\"{dataset}:\")\n",
    "    validate_classifiers(base_model, surrogate_model, test_data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine:\n",
      "Saving models ...\n",
      "epoch: 1, train loss: 0.537\n",
      "Saving models ...\n",
      "epoch: 2, train loss: 0.459\n",
      "Saving models ...\n",
      "epoch: 3, train loss: 0.436\n",
      "Saving models ...\n",
      "epoch: 4, train loss: 0.422\n",
      "Saving models ...\n",
      "epoch: 5, train loss: 0.406\n",
      "Saving models ...\n",
      "epoch: 6, train loss: 0.392\n",
      "Saving models ...\n",
      "epoch: 7, train loss: 0.381\n",
      "Saving models ...\n",
      "epoch: 8, train loss: 0.370\n",
      "Saving models ...\n",
      "epoch: 9, train loss: 0.360\n",
      "Saving models ...\n",
      "epoch: 10, train loss: 0.350\n",
      "Saving models ...\n",
      "epoch: 11, train loss: 0.340\n",
      "Saving models ...\n",
      "epoch: 12, train loss: 0.330\n",
      "Saving models ...\n",
      "epoch: 13, train loss: 0.321\n",
      "Saving models ...\n",
      "epoch: 14, train loss: 0.312\n",
      "Saving models ...\n",
      "epoch: 15, train loss: 0.305\n",
      "Saving models ...\n",
      "epoch: 16, train loss: 0.298\n",
      "Saving models ...\n",
      "epoch: 17, train loss: 0.291\n",
      "Saving models ...\n",
      "epoch: 18, train loss: 0.285\n",
      "Saving models ...\n",
      "epoch: 19, train loss: 0.281\n",
      "Saving models ...\n",
      "epoch: 20, train loss: 0.276\n",
      "Saving models ...\n",
      "epoch: 21, train loss: 0.270\n",
      "Saving models ...\n",
      "epoch: 22, train loss: 0.265\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 23, train loss: 0.266\n",
      "Saving models ...\n",
      "epoch: 24, train loss: 0.263\n",
      "Saving models ...\n",
      "epoch: 25, train loss: 0.259\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 26, train loss: 0.262\n",
      "Saving models ...\n",
      "epoch: 27, train loss: 0.252\n",
      "Saving models ...\n",
      "epoch: 28, train loss: 0.247\n",
      "Saving models ...\n",
      "epoch: 29, train loss: 0.244\n",
      "Saving models ...\n",
      "epoch: 30, train loss: 0.239\n",
      "Saving models ...\n",
      "epoch: 31, train loss: 0.237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 32, train loss: 0.240\n",
      "Saving models ...\n",
      "epoch: 33, train loss: 0.235\n",
      "Saving models ...\n",
      "epoch: 34, train loss: 0.229\n",
      "Saving models ...\n",
      "epoch: 35, train loss: 0.226\n",
      "Saving models ...\n",
      "epoch: 36, train loss: 0.220\n",
      "Saving models ...\n",
      "epoch: 37, train loss: 0.216\n",
      "Saving models ...\n",
      "epoch: 38, train loss: 0.214\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 39, train loss: 0.216\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 40, train loss: 0.216\n",
      "Saving models ...\n",
      "epoch: 41, train loss: 0.213\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 42, train loss: 0.223\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 43, train loss: 0.217\n",
      "Saving models ...\n",
      "epoch: 44, train loss: 0.207\n",
      "Saving models ...\n",
      "epoch: 45, train loss: 0.204\n",
      "Saving models ...\n",
      "epoch: 46, train loss: 0.200\n",
      "Saving models ...\n",
      "epoch: 47, train loss: 0.199\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 48, train loss: 0.200\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 49, train loss: 0.200\n",
      "Saving models ...\n",
      "epoch: 50, train loss: 0.197\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 51, train loss: 0.201\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 52, train loss: 0.203\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 53, train loss: 0.201\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 54, train loss: 0.197\n",
      "Saving models ...\n",
      "epoch: 55, train loss: 0.195\n",
      "Saving models ...\n",
      "epoch: 56, train loss: 0.191\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 57, train loss: 0.192\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 58, train loss: 0.193\n",
      "Saving models ...\n",
      "epoch: 59, train loss: 0.190\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 60, train loss: 0.195\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 61, train loss: 0.191\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 62, train loss: 0.192\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 63, train loss: 0.193\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 64, train loss: 0.190\n",
      "Saving models ...\n",
      "epoch: 65, train loss: 0.190\n",
      "Saving models ...\n",
      "epoch: 66, train loss: 0.189\n",
      "Saving models ...\n",
      "epoch: 67, train loss: 0.189\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 68, train loss: 0.190\n",
      "Saving models ...\n",
      "epoch: 69, train loss: 0.188\n",
      "Saving models ...\n",
      "epoch: 70, train loss: 0.186\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 71, train loss: 0.189\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 72, train loss: 0.189\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 73, train loss: 0.187\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 74, train loss: 0.189\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 75, train loss: 0.190\n",
      "Saving models ...\n",
      "epoch: 76, train loss: 0.186\n",
      "Saving models ...\n",
      "epoch: 77, train loss: 0.185\n",
      "Saving models ...\n",
      "epoch: 78, train loss: 0.184\n",
      "Saving models ...\n",
      "epoch: 79, train loss: 0.183\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 80, train loss: 0.183\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 81, train loss: 0.183\n",
      "Saving models ...\n",
      "epoch: 82, train loss: 0.181\n",
      "Saving models ...\n",
      "epoch: 83, train loss: 0.180\n",
      "Saving models ...\n",
      "epoch: 84, train loss: 0.178\n",
      "Saving models ...\n",
      "epoch: 85, train loss: 0.178\n",
      "Saving models ...\n",
      "epoch: 86, train loss: 0.177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 87, train loss: 0.178\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 88, train loss: 0.180\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 89, train loss: 0.178\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 90, train loss: 0.179\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 91, train loss: 0.181\n",
      "EarlyStopping counter: 6 out of 10\n",
      "epoch: 92, train loss: 0.180\n",
      "EarlyStopping counter: 7 out of 10\n",
      "epoch: 93, train loss: 0.178\n",
      "EarlyStopping counter: 8 out of 10\n",
      "epoch: 94, train loss: 0.179\n",
      "EarlyStopping counter: 9 out of 10\n",
      "epoch: 95, train loss: 0.177\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "\n",
      "housing:\n",
      "Saving models ...\n",
      "epoch: 1, train loss: 0.326\n",
      "Saving models ...\n",
      "epoch: 2, train loss: 0.248\n",
      "Saving models ...\n",
      "epoch: 3, train loss: 0.217\n",
      "Saving models ...\n",
      "epoch: 4, train loss: 0.196\n",
      "Saving models ...\n",
      "epoch: 5, train loss: 0.181\n",
      "Saving models ...\n",
      "epoch: 6, train loss: 0.172\n",
      "Saving models ...\n",
      "epoch: 7, train loss: 0.164\n",
      "Saving models ...\n",
      "epoch: 8, train loss: 0.159\n",
      "Saving models ...\n",
      "epoch: 9, train loss: 0.155\n",
      "Saving models ...\n",
      "epoch: 10, train loss: 0.152\n",
      "Saving models ...\n",
      "epoch: 11, train loss: 0.149\n",
      "Saving models ...\n",
      "epoch: 12, train loss: 0.147\n",
      "Saving models ...\n",
      "epoch: 13, train loss: 0.145\n",
      "Saving models ...\n",
      "epoch: 14, train loss: 0.144\n",
      "Saving models ...\n",
      "epoch: 15, train loss: 0.142\n",
      "Saving models ...\n",
      "epoch: 16, train loss: 0.141\n",
      "Saving models ...\n",
      "epoch: 17, train loss: 0.140\n",
      "Saving models ...\n",
      "epoch: 18, train loss: 0.139\n",
      "Saving models ...\n",
      "epoch: 19, train loss: 0.138\n",
      "Saving models ...\n",
      "epoch: 20, train loss: 0.138\n",
      "Saving models ...\n",
      "epoch: 21, train loss: 0.137\n",
      "Saving models ...\n",
      "epoch: 22, train loss: 0.137\n",
      "Saving models ...\n",
      "epoch: 23, train loss: 0.136\n",
      "Saving models ...\n",
      "epoch: 24, train loss: 0.135\n",
      "Saving models ...\n",
      "epoch: 25, train loss: 0.135\n",
      "Saving models ...\n",
      "epoch: 26, train loss: 0.135\n",
      "Saving models ...\n",
      "epoch: 27, train loss: 0.135\n",
      "Saving models ...\n",
      "epoch: 28, train loss: 0.134\n",
      "Saving models ...\n",
      "epoch: 29, train loss: 0.134\n",
      "Saving models ...\n",
      "epoch: 30, train loss: 0.133\n",
      "Saving models ...\n",
      "epoch: 31, train loss: 0.133\n",
      "Saving models ...\n",
      "epoch: 32, train loss: 0.133\n",
      "Saving models ...\n",
      "epoch: 33, train loss: 0.132\n",
      "Saving models ...\n",
      "epoch: 34, train loss: 0.132\n",
      "Saving models ...\n",
      "epoch: 35, train loss: 0.132\n",
      "Saving models ...\n",
      "epoch: 36, train loss: 0.132\n",
      "Saving models ...\n",
      "epoch: 37, train loss: 0.131\n",
      "Saving models ...\n",
      "epoch: 38, train loss: 0.131\n",
      "Saving models ...\n",
      "epoch: 39, train loss: 0.130\n",
      "Saving models ...\n",
      "epoch: 40, train loss: 0.130\n",
      "Saving models ...\n",
      "epoch: 41, train loss: 0.130\n",
      "Saving models ...\n",
      "epoch: 42, train loss: 0.130\n",
      "Saving models ...\n",
      "epoch: 43, train loss: 0.129\n",
      "Saving models ...\n",
      "epoch: 44, train loss: 0.129\n",
      "Saving models ...\n",
      "epoch: 45, train loss: 0.129\n",
      "Saving models ...\n",
      "epoch: 46, train loss: 0.128\n",
      "Saving models ...\n",
      "epoch: 47, train loss: 0.128\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 48, train loss: 0.128\n",
      "Saving models ...\n",
      "epoch: 49, train loss: 0.128\n",
      "Saving models ...\n",
      "epoch: 50, train loss: 0.128\n",
      "Saving models ...\n",
      "epoch: 51, train loss: 0.127\n",
      "Saving models ...\n",
      "epoch: 52, train loss: 0.127\n",
      "Saving models ...\n",
      "epoch: 53, train loss: 0.127\n",
      "Saving models ...\n",
      "epoch: 54, train loss: 0.127\n",
      "Saving models ...\n",
      "epoch: 55, train loss: 0.127\n",
      "Saving models ...\n",
      "epoch: 56, train loss: 0.126\n",
      "Saving models ...\n",
      "epoch: 57, train loss: 0.125\n",
      "Saving models ...\n",
      "epoch: 58, train loss: 0.125\n",
      "Saving models ...\n",
      "epoch: 59, train loss: 0.125\n",
      "Saving models ...\n",
      "epoch: 60, train loss: 0.124\n",
      "Saving models ...\n",
      "epoch: 61, train loss: 0.124\n",
      "Saving models ...\n",
      "epoch: 62, train loss: 0.124\n",
      "Saving models ...\n",
      "epoch: 63, train loss: 0.123\n",
      "Saving models ...\n",
      "epoch: 64, train loss: 0.123\n",
      "Saving models ...\n",
      "epoch: 65, train loss: 0.123\n",
      "Saving models ...\n",
      "epoch: 66, train loss: 0.122\n",
      "Saving models ...\n",
      "epoch: 67, train loss: 0.122\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 68, train loss: 0.122\n",
      "Saving models ...\n",
      "epoch: 69, train loss: 0.122\n",
      "Saving models ...\n",
      "epoch: 70, train loss: 0.122\n",
      "Saving models ...\n",
      "epoch: 71, train loss: 0.121\n",
      "Saving models ...\n",
      "epoch: 72, train loss: 0.121\n",
      "Saving models ...\n",
      "epoch: 73, train loss: 0.121\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 74, train loss: 0.121\n",
      "Saving models ...\n",
      "epoch: 75, train loss: 0.120\n",
      "Saving models ...\n",
      "epoch: 76, train loss: 0.120\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 77, train loss: 0.120\n",
      "Saving models ...\n",
      "epoch: 78, train loss: 0.120\n",
      "Saving models ...\n",
      "epoch: 79, train loss: 0.119\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 80, train loss: 0.119\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 81, train loss: 0.120\n",
      "Saving models ...\n",
      "epoch: 82, train loss: 0.119\n",
      "Saving models ...\n",
      "epoch: 83, train loss: 0.118\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 84, train loss: 0.118\n",
      "Saving models ...\n",
      "epoch: 85, train loss: 0.118\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 86, train loss: 0.118\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 87, train loss: 0.118\n",
      "Saving models ...\n",
      "epoch: 88, train loss: 0.117\n",
      "Saving models ...\n",
      "epoch: 89, train loss: 0.117\n",
      "Saving models ...\n",
      "epoch: 90, train loss: 0.117\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 91, train loss: 0.118\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 92, train loss: 0.118\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 93, train loss: 0.118\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 94, train loss: 0.118\n",
      "Saving models ...\n",
      "epoch: 95, train loss: 0.117\n",
      "Saving models ...\n",
      "epoch: 96, train loss: 0.117\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 97, train loss: 0.117\n",
      "Saving models ...\n",
      "epoch: 98, train loss: 0.116\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 99, train loss: 0.116\n",
      "Saving models ...\n",
      "epoch: 100, train loss: 0.116\n",
      "\n",
      "autompg:\n",
      "Saving models ...\n",
      "epoch: 1, train loss: 0.679\n",
      "Saving models ...\n",
      "epoch: 2, train loss: 0.651\n",
      "Saving models ...\n",
      "epoch: 3, train loss: 0.629\n",
      "Saving models ...\n",
      "epoch: 4, train loss: 0.609\n",
      "Saving models ...\n",
      "epoch: 5, train loss: 0.594\n",
      "Saving models ...\n",
      "epoch: 6, train loss: 0.580\n",
      "Saving models ...\n",
      "epoch: 7, train loss: 0.566\n",
      "Saving models ...\n",
      "epoch: 8, train loss: 0.553\n",
      "Saving models ...\n",
      "epoch: 9, train loss: 0.541\n",
      "Saving models ...\n",
      "epoch: 10, train loss: 0.531\n",
      "Saving models ...\n",
      "epoch: 11, train loss: 0.520\n",
      "Saving models ...\n",
      "epoch: 12, train loss: 0.509\n",
      "Saving models ...\n",
      "epoch: 13, train loss: 0.499\n",
      "Saving models ...\n",
      "epoch: 14, train loss: 0.489\n",
      "Saving models ...\n",
      "epoch: 15, train loss: 0.479\n",
      "Saving models ...\n",
      "epoch: 16, train loss: 0.470\n",
      "Saving models ...\n",
      "epoch: 17, train loss: 0.460\n",
      "Saving models ...\n",
      "epoch: 18, train loss: 0.451\n",
      "Saving models ...\n",
      "epoch: 19, train loss: 0.442\n",
      "Saving models ...\n",
      "epoch: 20, train loss: 0.434\n",
      "Saving models ...\n",
      "epoch: 21, train loss: 0.425\n",
      "Saving models ...\n",
      "epoch: 22, train loss: 0.416\n",
      "Saving models ...\n",
      "epoch: 23, train loss: 0.409\n",
      "Saving models ...\n",
      "epoch: 24, train loss: 0.401\n",
      "Saving models ...\n",
      "epoch: 25, train loss: 0.393\n",
      "Saving models ...\n",
      "epoch: 26, train loss: 0.385\n",
      "Saving models ...\n",
      "epoch: 27, train loss: 0.377\n",
      "Saving models ...\n",
      "epoch: 28, train loss: 0.370\n",
      "Saving models ...\n",
      "epoch: 29, train loss: 0.363\n",
      "Saving models ...\n",
      "epoch: 30, train loss: 0.356\n",
      "Saving models ...\n",
      "epoch: 31, train loss: 0.349\n",
      "Saving models ...\n",
      "epoch: 32, train loss: 0.342\n",
      "Saving models ...\n",
      "epoch: 33, train loss: 0.336\n",
      "Saving models ...\n",
      "epoch: 34, train loss: 0.331\n",
      "Saving models ...\n",
      "epoch: 35, train loss: 0.324\n",
      "Saving models ...\n",
      "epoch: 36, train loss: 0.318\n",
      "Saving models ...\n",
      "epoch: 37, train loss: 0.312\n",
      "Saving models ...\n",
      "epoch: 38, train loss: 0.306\n",
      "Saving models ...\n",
      "epoch: 39, train loss: 0.301\n",
      "Saving models ...\n",
      "epoch: 40, train loss: 0.295\n",
      "Saving models ...\n",
      "epoch: 41, train loss: 0.289\n",
      "Saving models ...\n",
      "epoch: 42, train loss: 0.284\n",
      "Saving models ...\n",
      "epoch: 43, train loss: 0.279\n",
      "Saving models ...\n",
      "epoch: 44, train loss: 0.273\n",
      "Saving models ...\n",
      "epoch: 45, train loss: 0.269\n",
      "Saving models ...\n",
      "epoch: 46, train loss: 0.264\n",
      "Saving models ...\n",
      "epoch: 47, train loss: 0.260\n",
      "Saving models ...\n",
      "epoch: 48, train loss: 0.255\n",
      "Saving models ...\n",
      "epoch: 49, train loss: 0.250\n",
      "Saving models ...\n",
      "epoch: 50, train loss: 0.246\n",
      "Saving models ...\n",
      "epoch: 51, train loss: 0.241\n",
      "Saving models ...\n",
      "epoch: 52, train loss: 0.238\n",
      "Saving models ...\n",
      "epoch: 53, train loss: 0.234\n",
      "Saving models ...\n",
      "epoch: 54, train loss: 0.229\n",
      "Saving models ...\n",
      "epoch: 55, train loss: 0.226\n",
      "Saving models ...\n",
      "epoch: 56, train loss: 0.222\n",
      "Saving models ...\n",
      "epoch: 57, train loss: 0.219\n",
      "Saving models ...\n",
      "epoch: 58, train loss: 0.217\n",
      "Saving models ...\n",
      "epoch: 59, train loss: 0.212\n",
      "Saving models ...\n",
      "epoch: 60, train loss: 0.209\n",
      "Saving models ...\n",
      "epoch: 61, train loss: 0.205\n",
      "Saving models ...\n",
      "epoch: 62, train loss: 0.203\n",
      "Saving models ...\n",
      "epoch: 63, train loss: 0.199\n",
      "Saving models ...\n",
      "epoch: 64, train loss: 0.196\n",
      "Saving models ...\n",
      "epoch: 65, train loss: 0.192\n",
      "Saving models ...\n",
      "epoch: 66, train loss: 0.190\n",
      "Saving models ...\n",
      "epoch: 67, train loss: 0.187\n",
      "Saving models ...\n",
      "epoch: 68, train loss: 0.184\n",
      "Saving models ...\n",
      "epoch: 69, train loss: 0.181\n",
      "Saving models ...\n",
      "epoch: 70, train loss: 0.179\n",
      "Saving models ...\n",
      "epoch: 71, train loss: 0.176\n",
      "Saving models ...\n",
      "epoch: 72, train loss: 0.174\n",
      "Saving models ...\n",
      "epoch: 73, train loss: 0.172\n",
      "Saving models ...\n",
      "epoch: 74, train loss: 0.170\n",
      "Saving models ...\n",
      "epoch: 75, train loss: 0.168\n",
      "Saving models ...\n",
      "epoch: 76, train loss: 0.165\n",
      "Saving models ...\n",
      "epoch: 77, train loss: 0.164\n",
      "Saving models ...\n",
      "epoch: 78, train loss: 0.161\n",
      "Saving models ...\n",
      "epoch: 79, train loss: 0.160\n",
      "Saving models ...\n",
      "epoch: 80, train loss: 0.157\n",
      "Saving models ...\n",
      "epoch: 81, train loss: 0.154\n",
      "Saving models ...\n",
      "epoch: 82, train loss: 0.152\n",
      "Saving models ...\n",
      "epoch: 83, train loss: 0.151\n",
      "Saving models ...\n",
      "epoch: 84, train loss: 0.149\n",
      "Saving models ...\n",
      "epoch: 85, train loss: 0.146\n",
      "Saving models ...\n",
      "epoch: 86, train loss: 0.145\n",
      "Saving models ...\n",
      "epoch: 87, train loss: 0.143\n",
      "Saving models ...\n",
      "epoch: 88, train loss: 0.142\n",
      "Saving models ...\n",
      "epoch: 89, train loss: 0.141\n",
      "Saving models ...\n",
      "epoch: 90, train loss: 0.138\n",
      "Saving models ...\n",
      "epoch: 91, train loss: 0.137\n",
      "Saving models ...\n",
      "epoch: 92, train loss: 0.136\n",
      "Saving models ...\n",
      "epoch: 93, train loss: 0.135\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 94, train loss: 0.136\n",
      "Saving models ...\n",
      "epoch: 95, train loss: 0.132\n",
      "Saving models ...\n",
      "epoch: 96, train loss: 0.132\n",
      "Saving models ...\n",
      "epoch: 97, train loss: 0.130\n",
      "Saving models ...\n",
      "epoch: 98, train loss: 0.129\n",
      "Saving models ...\n",
      "epoch: 99, train loss: 0.126\n",
      "Saving models ...\n",
      "epoch: 100, train loss: 0.125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regression_data = {\n",
    "    \"wine\": (wine_train, wine_test),\n",
    "    \"housing\": (housing_train, housing_test),\n",
    "    \"autompg\": (autompg_train, autompg_test)\n",
    "}\n",
    "regressors = []\n",
    "\n",
    "for dataset in regression_data.keys():\n",
    "    train_data, test_data = regression_data[dataset]\n",
    "    base_regressor = BaseRegressor(\n",
    "        input_dim=train_data.features.shape[1], output_dim=1, n_hidden_layers=4, layer_size=128).to(device)\n",
    "    surrogate_regressor = SurrogateRegressor(input_dim=train_data.features.shape[1], output_dim=1).to(device)\n",
    "    print(f\"{dataset}:\")\n",
    "    early_stopping = EarlyStopping(dir=save_dir, dataset_name=dataset, patience=patience, verbose=False)\n",
    "    train(base_regressor, surrogate_regressor, train_data, regression_criterion, epochs, alpha, early_stopping)\n",
    "    regressors.append((base_regressor, surrogate_regressor))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine:\n",
      "test mse: 0.275\n",
      "global fidelity: 0.170, global neighborhood fidelity: 0.160\n",
      "\n",
      "housing:\n",
      "test mse: 0.189\n",
      "global fidelity: 0.065, global neighborhood fidelity: 0.079\n",
      "\n",
      "autompg:\n",
      "test mse: 0.135\n",
      "global fidelity: 0.114, global neighborhood fidelity: 0.115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, dataset in enumerate(regression_data.keys()):\n",
    "    test_data = regression_data[dataset][1]\n",
    "    \n",
    "    base_model = BaseRegressor(\n",
    "        input_dim=test_data.features.shape[1], output_dim=1, n_hidden_layers=4, layer_size=128).to(device)\n",
    "    surrogate_model = SurrogateRegressor(input_dim=test_data.features.shape[1], output_dim=1).to(device)\n",
    "    \n",
    "    base_model.load_state_dict(torch.load(f\"{save_dir}/{dataset}/base_model_checkpoint.pt\"))\n",
    "    surrogate_model.load_state_dict(torch.load(f\"{save_dir}/{dataset}/surrogate_model_checkpoint.pt\"))\n",
    "    \n",
    "    base_model.eval()\n",
    "    surrogate_model.eval()\n",
    "    \n",
    "    print(f\"{dataset}:\")\n",
    "    validate_regressors(base_model, surrogate_model, test_data)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
