{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from early_stopping import EarlyStopping\n",
    "from log_cosh_loss import LogCoshLoss\n",
    "\n",
    "from datasets import CaliforniaHousingDataset, AdultDataset, TitanicDataset, AutoMpgDataset, WineDataset\n",
    "from metrics import calculate_global_fidelity, calculate_global_neighborhood_fidelity\n",
    "from models.base_model import BaseClassifier, BaseRegressor\n",
    "from models.surrogate_model import SurrogateClassifier, SurrogateRegressor\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "housing_train = CaliforniaHousingDataset(\n",
    "    dataset_path=\"data/california_housing/cal_housing.data\", normalize=True, train=True)\n",
    "housing_test = CaliforniaHousingDataset(\n",
    "    dataset_path=\"data/california_housing/cal_housing.data\", normalize=True, train=False)\n",
    "\n",
    "adult_train = AdultDataset(dataset_path=\"data/adult/adult.data\", normalize=True, train=True)\n",
    "adult_test = AdultDataset(dataset_path=\"data/adult/adult.data\", normalize=True, train=False)\n",
    "\n",
    "titanic_train = TitanicDataset(dataset_path=\"data/titanic/titanic.arff\", normalize=True, train=True)\n",
    "titanic_test = TitanicDataset(dataset_path=\"data/titanic/titanic.arff\", normalize=True, train=False)\n",
    "\n",
    "wine_train = WineDataset(dataset_path=\"data/wines/winequality-red.csv\", normalize=True, train=True)\n",
    "wine_test = WineDataset(dataset_path=\"data/wines/winequality-red.csv\", normalize=True, train=False)\n",
    "\n",
    "autompg_train = AutoMpgDataset(dataset_path=\"data/autompg/auto-mpg.data\", normalize=True, train=True)\n",
    "autompg_test = AutoMpgDataset(dataset_path=\"data/autompg/auto-mpg.data\", normalize=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 128  # not from the paper\n",
    "binary_classification_criterion = torch.nn.BCELoss()\n",
    "regression_criterion = LogCoshLoss() # \"logarithm of the hyperbolic cosine\" from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "        base_model: nn.Module,\n",
    "        surrogate_model: nn.Module,\n",
    "        train_data: Dataset,\n",
    "        criterion,\n",
    "        epochs: int,\n",
    "        alpha: float,\n",
    "        early_stopping: EarlyStopping = None\n",
    "):\n",
    "    params = list(base_model.parameters()) + list(surrogate_model.parameters())\n",
    "    optimizer = Adam(params, lr=lr)\n",
    "    loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for data, labels in loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            labels = labels.reshape(-1, 1)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            base_model_preds = base_model(data)\n",
    "            surrogate_model_preds = surrogate_model(data)\n",
    "            loss = criterion(base_model_preds, labels)\n",
    "            point_fidelity = calculate_global_fidelity(base_model_preds, surrogate_model_preds)\n",
    "            mtl_loss = alpha * loss + (1 - alpha) * point_fidelity\n",
    "        \n",
    "            mtl_loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += mtl_loss\n",
    "        \n",
    "        train_loss = running_loss / len(loader)\n",
    "        if early_stopping is not None:\n",
    "            early_stopping(train_loss, base_model, surrogate_model)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "        print(f\"epoch: {epoch + 1}, train loss: {train_loss:.3f}\")\n",
    "\n",
    "\n",
    "def validate_base_classifier(\n",
    "        model: nn.Module,\n",
    "        test_data: Dataset,\n",
    "):\n",
    "    loader = DataLoader(test_data, batch_size=len(test_data))\n",
    "    with torch.no_grad():\n",
    "        data, labels = next(iter(loader))\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        labels = labels.reshape(-1, 1)\n",
    "        preds_proba = model(data)\n",
    "        preds = torch.where(preds_proba >= 0.5, 1, 0)\n",
    "        accuracy = sklearn.metrics.accuracy_score(labels.cpu(), preds.cpu())\n",
    "        f1_score = sklearn.metrics.f1_score(labels.cpu(), preds.cpu())\n",
    "        print(f\"test accuracy: {accuracy:.3f}, f1 score: {f1_score:.3f}\")\n",
    "\n",
    "\n",
    "def validate_base_regressor(\n",
    "        model: nn.Module,\n",
    "        test_data: Dataset\n",
    "):\n",
    "    loader = DataLoader(test_data, batch_size=len(test_data))\n",
    "    with torch.no_grad():\n",
    "        data, labels = next(iter(loader))\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        labels = labels.reshape(-1, 1)\n",
    "        preds = model(data)\n",
    "        mse = sklearn.metrics.mean_squared_error(labels.cpu(), preds.cpu())\n",
    "        print(f\"test mse: {mse:.3f}\")\n",
    "\n",
    "\n",
    "def validate_surrogate_model(\n",
    "        base_model: nn.Module,\n",
    "        surrogate_model: nn.Module,\n",
    "        test_data: Dataset\n",
    "):\n",
    "    loader = DataLoader(test_data, batch_size=len(test_data))\n",
    "    with torch.no_grad():\n",
    "        data, _ = next(iter(loader))\n",
    "        data = data.to(device)\n",
    "        base_model_preds = base_model(data)\n",
    "        surrogate_model_preds = surrogate_model(data)\n",
    "        global_fidelity = calculate_global_fidelity(base_model_preds, surrogate_model_preds)\n",
    "        global_neighborhood_fidelity = calculate_global_neighborhood_fidelity(base_model, surrogate_model, data)\n",
    "        print(f\"global fidelity: {global_fidelity:.3f}, global neighborhood fidelity: {global_neighborhood_fidelity:.3f}\")\n",
    "\n",
    "\n",
    "def validate_regressors(\n",
    "        base_model: nn.Module,\n",
    "        surrogate_model: nn.Module,\n",
    "        test_data: Dataset\n",
    "):\n",
    "    validate_base_regressor(base_model, test_data)\n",
    "    validate_surrogate_model(base_model, surrogate_model, test_data)\n",
    "\n",
    "\n",
    "def validate_classifiers(\n",
    "        base_model: nn.Module,\n",
    "        surrogate_model: nn.Module,\n",
    "        test_data: Dataset\n",
    "):\n",
    "    validate_base_classifier(base_model, test_data)\n",
    "    validate_surrogate_model(base_model, surrogate_model, test_data)\n",
    "\n",
    "# TODO local explainability evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult:\n",
      "Saving models ...\n",
      "epoch: 1, train loss: 0.220\n",
      "Saving models ...\n",
      "epoch: 2, train loss: 0.181\n",
      "Saving models ...\n",
      "epoch: 3, train loss: 0.171\n",
      "Saving models ...\n",
      "epoch: 4, train loss: 0.165\n",
      "Saving models ...\n",
      "epoch: 5, train loss: 0.160\n",
      "Saving models ...\n",
      "epoch: 6, train loss: 0.156\n",
      "Saving models ...\n",
      "epoch: 7, train loss: 0.153\n",
      "Saving models ...\n",
      "epoch: 8, train loss: 0.151\n",
      "Saving models ...\n",
      "epoch: 9, train loss: 0.149\n",
      "Saving models ...\n",
      "epoch: 10, train loss: 0.147\n",
      "Saving models ...\n",
      "epoch: 11, train loss: 0.146\n",
      "Saving models ...\n",
      "epoch: 12, train loss: 0.144\n",
      "Saving models ...\n",
      "epoch: 13, train loss: 0.143\n",
      "Saving models ...\n",
      "epoch: 14, train loss: 0.141\n",
      "Saving models ...\n",
      "epoch: 15, train loss: 0.139\n",
      "Saving models ...\n",
      "epoch: 16, train loss: 0.139\n",
      "Saving models ...\n",
      "epoch: 17, train loss: 0.137\n",
      "Saving models ...\n",
      "epoch: 18, train loss: 0.135\n",
      "Saving models ...\n",
      "epoch: 19, train loss: 0.134\n",
      "Saving models ...\n",
      "epoch: 20, train loss: 0.133\n",
      "Saving models ...\n",
      "epoch: 21, train loss: 0.132\n",
      "Saving models ...\n",
      "epoch: 22, train loss: 0.130\n",
      "Saving models ...\n",
      "epoch: 23, train loss: 0.129\n",
      "Saving models ...\n",
      "epoch: 24, train loss: 0.126\n",
      "Saving models ...\n",
      "epoch: 25, train loss: 0.125\n",
      "Saving models ...\n",
      "epoch: 26, train loss: 0.124\n",
      "Saving models ...\n",
      "epoch: 27, train loss: 0.123\n",
      "Saving models ...\n",
      "epoch: 28, train loss: 0.121\n",
      "Saving models ...\n",
      "epoch: 29, train loss: 0.120\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 30, train loss: 0.120\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 31, train loss: 0.120\n",
      "Saving models ...\n",
      "epoch: 32, train loss: 0.119\n",
      "Saving models ...\n",
      "epoch: 33, train loss: 0.115\n",
      "Saving models ...\n",
      "epoch: 34, train loss: 0.114\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 35, train loss: 0.115\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 36, train loss: 0.115\n",
      "Saving models ...\n",
      "epoch: 37, train loss: 0.111\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 38, train loss: 0.115\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 39, train loss: 0.112\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 40, train loss: 0.111\n",
      "Saving models ...\n",
      "epoch: 41, train loss: 0.109\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 42, train loss: 0.110\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 43, train loss: 0.111\n",
      "Saving models ...\n",
      "epoch: 44, train loss: 0.107\n",
      "Saving models ...\n",
      "epoch: 45, train loss: 0.104\n",
      "Saving models ...\n",
      "epoch: 46, train loss: 0.103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 47, train loss: 0.104\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 48, train loss: 0.105\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 49, train loss: 0.104\n",
      "Saving models ...\n",
      "epoch: 50, train loss: 0.102\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 51, train loss: 0.103\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 52, train loss: 0.103\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 53, train loss: 0.104\n",
      "Saving models ...\n",
      "epoch: 54, train loss: 0.101\n",
      "Saving models ...\n",
      "epoch: 55, train loss: 0.098\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 56, train loss: 0.098\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 57, train loss: 0.101\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 58, train loss: 0.100\n",
      "Saving models ...\n",
      "epoch: 59, train loss: 0.097\n",
      "Saving models ...\n",
      "epoch: 60, train loss: 0.096\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 61, train loss: 0.098\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 62, train loss: 0.097\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 63, train loss: 0.096\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 64, train loss: 0.098\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 65, train loss: 0.097\n",
      "EarlyStopping counter: 6 out of 10\n",
      "epoch: 66, train loss: 0.096\n",
      "Saving models ...\n",
      "epoch: 67, train loss: 0.094\n",
      "Saving models ...\n",
      "epoch: 68, train loss: 0.093\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 69, train loss: 0.096\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 70, train loss: 0.098\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 71, train loss: 0.095\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 72, train loss: 0.094\n",
      "Saving models ...\n",
      "epoch: 73, train loss: 0.092\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 74, train loss: 0.092\n",
      "Saving models ...\n",
      "epoch: 75, train loss: 0.090\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 76, train loss: 0.093\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 77, train loss: 0.094\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 78, train loss: 0.093\n",
      "Saving models ...\n",
      "epoch: 79, train loss: 0.090\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 80, train loss: 0.091\n",
      "Saving models ...\n",
      "epoch: 81, train loss: 0.090\n",
      "Saving models ...\n",
      "epoch: 82, train loss: 0.089\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 83, train loss: 0.090\n",
      "Saving models ...\n",
      "epoch: 84, train loss: 0.088\n",
      "Saving models ...\n",
      "epoch: 85, train loss: 0.086\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 86, train loss: 0.087\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 87, train loss: 0.092\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 88, train loss: 0.091\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 89, train loss: 0.089\n",
      "Saving models ...\n",
      "epoch: 90, train loss: 0.086\n",
      "Saving models ...\n",
      "epoch: 91, train loss: 0.086\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 92, train loss: 0.086\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 93, train loss: 0.088\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 94, train loss: 0.090\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 95, train loss: 0.088\n",
      "Saving models ...\n",
      "epoch: 96, train loss: 0.085\n",
      "Saving models ...\n",
      "epoch: 97, train loss: 0.083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 98, train loss: 0.084\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 99, train loss: 0.086\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 100, train loss: 0.085\n",
      "\n",
      "titanic:\n",
      "Saving models ...\n",
      "epoch: 1, train loss: 0.477\n",
      "Saving models ...\n",
      "epoch: 2, train loss: 0.445\n",
      "Saving models ...\n",
      "epoch: 3, train loss: 0.441\n",
      "Saving models ...\n",
      "epoch: 4, train loss: 0.440\n",
      "Saving models ...\n",
      "epoch: 5, train loss: 0.437\n",
      "Saving models ...\n",
      "epoch: 6, train loss: 0.434\n",
      "Saving models ...\n",
      "epoch: 7, train loss: 0.432\n",
      "Saving models ...\n",
      "epoch: 8, train loss: 0.427\n",
      "Saving models ...\n",
      "epoch: 9, train loss: 0.423\n",
      "Saving models ...\n",
      "epoch: 10, train loss: 0.416\n",
      "Saving models ...\n",
      "epoch: 11, train loss: 0.406\n",
      "Saving models ...\n",
      "epoch: 12, train loss: 0.390\n",
      "Saving models ...\n",
      "epoch: 13, train loss: 0.368\n",
      "Saving models ...\n",
      "epoch: 14, train loss: 0.341\n",
      "Saving models ...\n",
      "epoch: 15, train loss: 0.324\n",
      "Saving models ...\n",
      "epoch: 16, train loss: 0.311\n",
      "Saving models ...\n",
      "epoch: 17, train loss: 0.297\n",
      "Saving models ...\n",
      "epoch: 18, train loss: 0.285\n",
      "Saving models ...\n",
      "epoch: 19, train loss: 0.277\n",
      "Saving models ...\n",
      "epoch: 20, train loss: 0.271\n",
      "Saving models ...\n",
      "epoch: 21, train loss: 0.264\n",
      "Saving models ...\n",
      "epoch: 22, train loss: 0.262\n",
      "Saving models ...\n",
      "epoch: 23, train loss: 0.257\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 24, train loss: 0.263\n",
      "Saving models ...\n",
      "epoch: 25, train loss: 0.256\n",
      "Saving models ...\n",
      "epoch: 26, train loss: 0.252\n",
      "Saving models ...\n",
      "epoch: 27, train loss: 0.252\n",
      "Saving models ...\n",
      "epoch: 28, train loss: 0.250\n",
      "Saving models ...\n",
      "epoch: 29, train loss: 0.248\n",
      "Saving models ...\n",
      "epoch: 30, train loss: 0.247\n",
      "Saving models ...\n",
      "epoch: 31, train loss: 0.246\n",
      "Saving models ...\n",
      "epoch: 32, train loss: 0.244\n",
      "Saving models ...\n",
      "epoch: 33, train loss: 0.243\n",
      "Saving models ...\n",
      "epoch: 34, train loss: 0.242\n",
      "Saving models ...\n",
      "epoch: 35, train loss: 0.242\n",
      "Saving models ...\n",
      "epoch: 36, train loss: 0.241\n",
      "Saving models ...\n",
      "epoch: 37, train loss: 0.240\n",
      "Saving models ...\n",
      "epoch: 38, train loss: 0.239\n",
      "Saving models ...\n",
      "epoch: 39, train loss: 0.238\n",
      "Saving models ...\n",
      "epoch: 40, train loss: 0.238\n",
      "Saving models ...\n",
      "epoch: 41, train loss: 0.237\n",
      "Saving models ...\n",
      "epoch: 42, train loss: 0.236\n",
      "Saving models ...\n",
      "epoch: 43, train loss: 0.236\n",
      "Saving models ...\n",
      "epoch: 44, train loss: 0.235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 45, train loss: 0.236\n",
      "Saving models ...\n",
      "epoch: 46, train loss: 0.234\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 47, train loss: 0.234\n",
      "Saving models ...\n",
      "epoch: 48, train loss: 0.232\n",
      "Saving models ...\n",
      "epoch: 49, train loss: 0.231\n",
      "Saving models ...\n",
      "epoch: 50, train loss: 0.231\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 51, train loss: 0.231\n",
      "Saving models ...\n",
      "epoch: 52, train loss: 0.229\n",
      "Saving models ...\n",
      "epoch: 53, train loss: 0.229\n",
      "Saving models ...\n",
      "epoch: 54, train loss: 0.228\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 55, train loss: 0.229\n",
      "Saving models ...\n",
      "epoch: 56, train loss: 0.227\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 57, train loss: 0.228\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 58, train loss: 0.228\n",
      "Saving models ...\n",
      "epoch: 59, train loss: 0.226\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 60, train loss: 0.227\n",
      "Saving models ...\n",
      "epoch: 61, train loss: 0.224\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 62, train loss: 0.226\n",
      "Saving models ...\n",
      "epoch: 63, train loss: 0.223\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 64, train loss: 0.224\n",
      "Saving models ...\n",
      "epoch: 65, train loss: 0.222\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 66, train loss: 0.222\n",
      "Saving models ...\n",
      "epoch: 67, train loss: 0.221\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 68, train loss: 0.221\n",
      "Saving models ...\n",
      "epoch: 69, train loss: 0.220\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 70, train loss: 0.221\n",
      "Saving models ...\n",
      "epoch: 71, train loss: 0.219\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 72, train loss: 0.222\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 73, train loss: 0.222\n",
      "Saving models ...\n",
      "epoch: 74, train loss: 0.219\n",
      "Saving models ...\n",
      "epoch: 75, train loss: 0.219\n",
      "Saving models ...\n",
      "epoch: 76, train loss: 0.218\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 77, train loss: 0.218\n",
      "Saving models ...\n",
      "epoch: 78, train loss: 0.217\n",
      "Saving models ...\n",
      "epoch: 79, train loss: 0.216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 80, train loss: 0.217\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 81, train loss: 0.219\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 82, train loss: 0.219\n",
      "Saving models ...\n",
      "epoch: 83, train loss: 0.216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 84, train loss: 0.218\n",
      "Saving models ...\n",
      "epoch: 85, train loss: 0.215\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 86, train loss: 0.218\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 87, train loss: 0.217\n",
      "Saving models ...\n",
      "epoch: 88, train loss: 0.215\n",
      "Saving models ...\n",
      "epoch: 89, train loss: 0.213\n",
      "Saving models ...\n",
      "epoch: 90, train loss: 0.213\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 91, train loss: 0.213\n",
      "Saving models ...\n",
      "epoch: 92, train loss: 0.211\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 93, train loss: 0.212\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 94, train loss: 0.211\n",
      "Saving models ...\n",
      "epoch: 95, train loss: 0.210\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 96, train loss: 0.210\n",
      "Saving models ...\n",
      "epoch: 97, train loss: 0.210\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 98, train loss: 0.211\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 99, train loss: 0.218\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 100, train loss: 0.214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "alpha = 0.5\n",
    "patience = 10  # for early stopping\n",
    "save_dir = \"checkpoints\"\n",
    "\n",
    "classification_data = {\n",
    "    \"adult\": (adult_train, adult_test),\n",
    "    \"titanic\": (titanic_train, titanic_test)\n",
    "}\n",
    "classifiers = []\n",
    "\n",
    "for dataset in classification_data.keys():\n",
    "    train_data, test_data = classification_data[dataset]\n",
    "    base_model = BaseClassifier(\n",
    "        input_dim=train_data.features.shape[1], output_dim=1, n_hidden_layers=4, layer_size=128).to(device)\n",
    "    surrogate_model = SurrogateClassifier(input_dim=train_data.features.shape[1], output_dim=1).to(device)\n",
    "    print(f\"{dataset}:\")\n",
    "    early_stopping = EarlyStopping(dir=save_dir, dataset_name=dataset, patience=patience, verbose=False)\n",
    "    train(base_model, surrogate_model, train_data, binary_classification_criterion, epochs, alpha, early_stopping)\n",
    "    classifiers.append((base_model, surrogate_model))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult:\n",
      "test accuracy: 0.922, f1 score: 0.833\n",
      "global fidelity: 0.052, global neighborhood fidelity: 0.054\n",
      "\n",
      "titanic:\n",
      "test accuracy: 0.804, f1 score: 0.725\n",
      "global fidelity: 0.021, global neighborhood fidelity: 0.021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, dataset in enumerate(classification_data.keys()):\n",
    "    test_data = classification_data[dataset][1]\n",
    "    \n",
    "    base_model = BaseClassifier(\n",
    "        input_dim=test_data.features.shape[1], output_dim=1, n_hidden_layers=4, layer_size=128).to(device)\n",
    "    surrogate_model = SurrogateClassifier(input_dim=test_data.features.shape[1], output_dim=1).to(device)\n",
    "    \n",
    "    base_model.load_state_dict(torch.load(f\"{save_dir}/{dataset}/base_model_checkpoint.pt\"))\n",
    "    surrogate_model.load_state_dict(torch.load(f\"{save_dir}/{dataset}/surrogate_model_checkpoint.pt\"))\n",
    "    \n",
    "    base_model.eval()\n",
    "    surrogate_model.eval()\n",
    "    \n",
    "    print(f\"{dataset}:\")\n",
    "    validate_classifiers(base_model, surrogate_model, test_data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine:\n",
      "Saving models ...\n",
      "epoch: 1, train loss: 0.339\n",
      "Saving models ...\n",
      "epoch: 2, train loss: 0.214\n",
      "Saving models ...\n",
      "epoch: 3, train loss: 0.194\n",
      "Saving models ...\n",
      "epoch: 4, train loss: 0.184\n",
      "Saving models ...\n",
      "epoch: 5, train loss: 0.180\n",
      "Saving models ...\n",
      "epoch: 6, train loss: 0.175\n",
      "Saving models ...\n",
      "epoch: 7, train loss: 0.171\n",
      "Saving models ...\n",
      "epoch: 8, train loss: 0.168\n",
      "Saving models ...\n",
      "epoch: 9, train loss: 0.164\n",
      "Saving models ...\n",
      "epoch: 10, train loss: 0.161\n",
      "Saving models ...\n",
      "epoch: 11, train loss: 0.158\n",
      "Saving models ...\n",
      "epoch: 12, train loss: 0.155\n",
      "Saving models ...\n",
      "epoch: 13, train loss: 0.153\n",
      "Saving models ...\n",
      "epoch: 14, train loss: 0.150\n",
      "Saving models ...\n",
      "epoch: 15, train loss: 0.148\n",
      "Saving models ...\n",
      "epoch: 16, train loss: 0.145\n",
      "Saving models ...\n",
      "epoch: 17, train loss: 0.143\n",
      "Saving models ...\n",
      "epoch: 18, train loss: 0.141\n",
      "Saving models ...\n",
      "epoch: 19, train loss: 0.139\n",
      "Saving models ...\n",
      "epoch: 20, train loss: 0.137\n",
      "Saving models ...\n",
      "epoch: 21, train loss: 0.135\n",
      "Saving models ...\n",
      "epoch: 22, train loss: 0.133\n",
      "Saving models ...\n",
      "epoch: 23, train loss: 0.132\n",
      "Saving models ...\n",
      "epoch: 24, train loss: 0.130\n",
      "Saving models ...\n",
      "epoch: 25, train loss: 0.129\n",
      "Saving models ...\n",
      "epoch: 26, train loss: 0.127\n",
      "Saving models ...\n",
      "epoch: 27, train loss: 0.126\n",
      "Saving models ...\n",
      "epoch: 28, train loss: 0.124\n",
      "Saving models ...\n",
      "epoch: 29, train loss: 0.123\n",
      "Saving models ...\n",
      "epoch: 30, train loss: 0.122\n",
      "Saving models ...\n",
      "epoch: 31, train loss: 0.121\n",
      "Saving models ...\n",
      "epoch: 32, train loss: 0.121\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 33, train loss: 0.122\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 34, train loss: 0.122\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 35, train loss: 0.123\n",
      "Saving models ...\n",
      "epoch: 36, train loss: 0.121\n",
      "Saving models ...\n",
      "epoch: 37, train loss: 0.119\n",
      "Saving models ...\n",
      "epoch: 38, train loss: 0.117\n",
      "Saving models ...\n",
      "epoch: 39, train loss: 0.115\n",
      "Saving models ...\n",
      "epoch: 40, train loss: 0.114\n",
      "Saving models ...\n",
      "epoch: 41, train loss: 0.114\n",
      "Saving models ...\n",
      "epoch: 42, train loss: 0.113\n",
      "Saving models ...\n",
      "epoch: 43, train loss: 0.111\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 44, train loss: 0.112\n",
      "Saving models ...\n",
      "epoch: 45, train loss: 0.111\n",
      "Saving models ...\n",
      "epoch: 46, train loss: 0.110\n",
      "Saving models ...\n",
      "epoch: 47, train loss: 0.110\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 48, train loss: 0.110\n",
      "Saving models ...\n",
      "epoch: 49, train loss: 0.110\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 50, train loss: 0.110\n",
      "Saving models ...\n",
      "epoch: 51, train loss: 0.110\n",
      "Saving models ...\n",
      "epoch: 52, train loss: 0.109\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 53, train loss: 0.109\n",
      "Saving models ...\n",
      "epoch: 54, train loss: 0.108\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 55, train loss: 0.108\n",
      "Saving models ...\n",
      "epoch: 56, train loss: 0.107\n",
      "Saving models ...\n",
      "epoch: 57, train loss: 0.107\n",
      "Saving models ...\n",
      "epoch: 58, train loss: 0.106\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 59, train loss: 0.106\n",
      "Saving models ...\n",
      "epoch: 60, train loss: 0.106\n",
      "Saving models ...\n",
      "epoch: 61, train loss: 0.106\n",
      "Saving models ...\n",
      "epoch: 62, train loss: 0.106\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 63, train loss: 0.106\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 64, train loss: 0.107\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 65, train loss: 0.110\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 66, train loss: 0.110\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 67, train loss: 0.109\n",
      "EarlyStopping counter: 6 out of 10\n",
      "epoch: 68, train loss: 0.107\n",
      "EarlyStopping counter: 7 out of 10\n",
      "epoch: 69, train loss: 0.107\n",
      "Saving models ...\n",
      "epoch: 70, train loss: 0.105\n",
      "Saving models ...\n",
      "epoch: 71, train loss: 0.104\n",
      "Saving models ...\n",
      "epoch: 72, train loss: 0.104\n",
      "Saving models ...\n",
      "epoch: 73, train loss: 0.104\n",
      "Saving models ...\n",
      "epoch: 74, train loss: 0.103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 75, train loss: 0.103\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 76, train loss: 0.103\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 77, train loss: 0.103\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 78, train loss: 0.103\n",
      "Saving models ...\n",
      "epoch: 79, train loss: 0.103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 80, train loss: 0.103\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 81, train loss: 0.103\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 82, train loss: 0.103\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 83, train loss: 0.103\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 84, train loss: 0.104\n",
      "EarlyStopping counter: 6 out of 10\n",
      "epoch: 85, train loss: 0.104\n",
      "EarlyStopping counter: 7 out of 10\n",
      "epoch: 86, train loss: 0.104\n",
      "EarlyStopping counter: 8 out of 10\n",
      "epoch: 87, train loss: 0.104\n",
      "EarlyStopping counter: 9 out of 10\n",
      "epoch: 88, train loss: 0.105\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "\n",
      "housing:\n",
      "Saving models ...\n",
      "epoch: 1, train loss: 0.210\n",
      "Saving models ...\n",
      "epoch: 2, train loss: 0.125\n",
      "Saving models ...\n",
      "epoch: 3, train loss: 0.093\n",
      "Saving models ...\n",
      "epoch: 4, train loss: 0.081\n",
      "Saving models ...\n",
      "epoch: 5, train loss: 0.076\n",
      "Saving models ...\n",
      "epoch: 6, train loss: 0.073\n",
      "Saving models ...\n",
      "epoch: 7, train loss: 0.071\n",
      "Saving models ...\n",
      "epoch: 8, train loss: 0.070\n",
      "Saving models ...\n",
      "epoch: 9, train loss: 0.070\n",
      "Saving models ...\n",
      "epoch: 10, train loss: 0.069\n",
      "Saving models ...\n",
      "epoch: 11, train loss: 0.068\n",
      "Saving models ...\n",
      "epoch: 12, train loss: 0.068\n",
      "Saving models ...\n",
      "epoch: 13, train loss: 0.067\n",
      "Saving models ...\n",
      "epoch: 14, train loss: 0.067\n",
      "Saving models ...\n",
      "epoch: 15, train loss: 0.066\n",
      "Saving models ...\n",
      "epoch: 16, train loss: 0.066\n",
      "Saving models ...\n",
      "epoch: 17, train loss: 0.066\n",
      "Saving models ...\n",
      "epoch: 18, train loss: 0.065\n",
      "Saving models ...\n",
      "epoch: 19, train loss: 0.065\n",
      "Saving models ...\n",
      "epoch: 20, train loss: 0.065\n",
      "Saving models ...\n",
      "epoch: 21, train loss: 0.065\n",
      "Saving models ...\n",
      "epoch: 22, train loss: 0.065\n",
      "Saving models ...\n",
      "epoch: 23, train loss: 0.064\n",
      "Saving models ...\n",
      "epoch: 24, train loss: 0.064\n",
      "Saving models ...\n",
      "epoch: 25, train loss: 0.064\n",
      "Saving models ...\n",
      "epoch: 26, train loss: 0.064\n",
      "Saving models ...\n",
      "epoch: 27, train loss: 0.064\n",
      "Saving models ...\n",
      "epoch: 28, train loss: 0.064\n",
      "Saving models ...\n",
      "epoch: 29, train loss: 0.064\n",
      "Saving models ...\n",
      "epoch: 30, train loss: 0.064\n",
      "Saving models ...\n",
      "epoch: 31, train loss: 0.064\n",
      "Saving models ...\n",
      "epoch: 32, train loss: 0.064\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 33, train loss: 0.064\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 34, train loss: 0.064\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 35, train loss: 0.064\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 36, train loss: 0.064\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 37, train loss: 0.064\n",
      "Saving models ...\n",
      "epoch: 38, train loss: 0.064\n",
      "Saving models ...\n",
      "epoch: 39, train loss: 0.063\n",
      "Saving models ...\n",
      "epoch: 40, train loss: 0.063\n",
      "Saving models ...\n",
      "epoch: 41, train loss: 0.063\n",
      "Saving models ...\n",
      "epoch: 42, train loss: 0.063\n",
      "Saving models ...\n",
      "epoch: 43, train loss: 0.063\n",
      "Saving models ...\n",
      "epoch: 44, train loss: 0.063\n",
      "Saving models ...\n",
      "epoch: 45, train loss: 0.063\n",
      "Saving models ...\n",
      "epoch: 46, train loss: 0.063\n",
      "Saving models ...\n",
      "epoch: 47, train loss: 0.063\n",
      "Saving models ...\n",
      "epoch: 48, train loss: 0.063\n",
      "Saving models ...\n",
      "epoch: 49, train loss: 0.062\n",
      "Saving models ...\n",
      "epoch: 50, train loss: 0.062\n",
      "Saving models ...\n",
      "epoch: 51, train loss: 0.062\n",
      "Saving models ...\n",
      "epoch: 52, train loss: 0.062\n",
      "Saving models ...\n",
      "epoch: 53, train loss: 0.062\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 54, train loss: 0.062\n",
      "Saving models ...\n",
      "epoch: 55, train loss: 0.062\n",
      "Saving models ...\n",
      "epoch: 56, train loss: 0.062\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 57, train loss: 0.062\n",
      "Saving models ...\n",
      "epoch: 58, train loss: 0.062\n",
      "Saving models ...\n",
      "epoch: 59, train loss: 0.062\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 60, train loss: 0.062\n",
      "Saving models ...\n",
      "epoch: 61, train loss: 0.062\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 62, train loss: 0.062\n",
      "Saving models ...\n",
      "epoch: 63, train loss: 0.062\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 64, train loss: 0.062\n",
      "Saving models ...\n",
      "epoch: 65, train loss: 0.062\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 66, train loss: 0.062\n",
      "Saving models ...\n",
      "epoch: 67, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 68, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 69, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 70, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 71, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 72, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 73, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 74, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 75, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 76, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 77, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 78, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 79, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 80, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 81, train loss: 0.061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 82, train loss: 0.061\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 83, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 84, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 85, train loss: 0.061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 86, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 87, train loss: 0.061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 88, train loss: 0.061\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 89, train loss: 0.061\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 90, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 91, train loss: 0.060\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 92, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 93, train loss: 0.060\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 94, train loss: 0.060\n",
      "Saving models ...\n",
      "epoch: 95, train loss: 0.060\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 96, train loss: 0.060\n",
      "Saving models ...\n",
      "epoch: 97, train loss: 0.060\n",
      "Saving models ...\n",
      "epoch: 98, train loss: 0.060\n",
      "Saving models ...\n",
      "epoch: 99, train loss: 0.060\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 100, train loss: 0.060\n",
      "\n",
      "autompg:\n",
      "Saving models ...\n",
      "epoch: 1, train loss: 0.357\n",
      "Saving models ...\n",
      "epoch: 2, train loss: 0.279\n",
      "Saving models ...\n",
      "epoch: 3, train loss: 0.184\n",
      "Saving models ...\n",
      "epoch: 4, train loss: 0.108\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 5, train loss: 0.116\n",
      "Saving models ...\n",
      "epoch: 6, train loss: 0.103\n",
      "Saving models ...\n",
      "epoch: 7, train loss: 0.086\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 8, train loss: 0.092\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 9, train loss: 0.086\n",
      "Saving models ...\n",
      "epoch: 10, train loss: 0.080\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 11, train loss: 0.081\n",
      "Saving models ...\n",
      "epoch: 12, train loss: 0.078\n",
      "Saving models ...\n",
      "epoch: 13, train loss: 0.076\n",
      "Saving models ...\n",
      "epoch: 14, train loss: 0.075\n",
      "Saving models ...\n",
      "epoch: 15, train loss: 0.073\n",
      "Saving models ...\n",
      "epoch: 16, train loss: 0.072\n",
      "Saving models ...\n",
      "epoch: 17, train loss: 0.071\n",
      "Saving models ...\n",
      "epoch: 18, train loss: 0.069\n",
      "Saving models ...\n",
      "epoch: 19, train loss: 0.068\n",
      "Saving models ...\n",
      "epoch: 20, train loss: 0.067\n",
      "Saving models ...\n",
      "epoch: 21, train loss: 0.066\n",
      "Saving models ...\n",
      "epoch: 22, train loss: 0.065\n",
      "Saving models ...\n",
      "epoch: 23, train loss: 0.064\n",
      "Saving models ...\n",
      "epoch: 24, train loss: 0.063\n",
      "Saving models ...\n",
      "epoch: 25, train loss: 0.063\n",
      "Saving models ...\n",
      "epoch: 26, train loss: 0.062\n",
      "Saving models ...\n",
      "epoch: 27, train loss: 0.061\n",
      "Saving models ...\n",
      "epoch: 28, train loss: 0.060\n",
      "Saving models ...\n",
      "epoch: 29, train loss: 0.059\n",
      "Saving models ...\n",
      "epoch: 30, train loss: 0.059\n",
      "Saving models ...\n",
      "epoch: 31, train loss: 0.058\n",
      "Saving models ...\n",
      "epoch: 32, train loss: 0.057\n",
      "Saving models ...\n",
      "epoch: 33, train loss: 0.056\n",
      "Saving models ...\n",
      "epoch: 34, train loss: 0.056\n",
      "Saving models ...\n",
      "epoch: 35, train loss: 0.055\n",
      "Saving models ...\n",
      "epoch: 36, train loss: 0.055\n",
      "Saving models ...\n",
      "epoch: 37, train loss: 0.054\n",
      "Saving models ...\n",
      "epoch: 38, train loss: 0.053\n",
      "Saving models ...\n",
      "epoch: 39, train loss: 0.053\n",
      "Saving models ...\n",
      "epoch: 40, train loss: 0.052\n",
      "Saving models ...\n",
      "epoch: 41, train loss: 0.052\n",
      "Saving models ...\n",
      "epoch: 42, train loss: 0.051\n",
      "Saving models ...\n",
      "epoch: 43, train loss: 0.051\n",
      "Saving models ...\n",
      "epoch: 44, train loss: 0.050\n",
      "Saving models ...\n",
      "epoch: 45, train loss: 0.050\n",
      "Saving models ...\n",
      "epoch: 46, train loss: 0.049\n",
      "Saving models ...\n",
      "epoch: 47, train loss: 0.049\n",
      "Saving models ...\n",
      "epoch: 48, train loss: 0.049\n",
      "Saving models ...\n",
      "epoch: 49, train loss: 0.048\n",
      "Saving models ...\n",
      "epoch: 50, train loss: 0.048\n",
      "Saving models ...\n",
      "epoch: 51, train loss: 0.047\n",
      "Saving models ...\n",
      "epoch: 52, train loss: 0.047\n",
      "Saving models ...\n",
      "epoch: 53, train loss: 0.047\n",
      "Saving models ...\n",
      "epoch: 54, train loss: 0.046\n",
      "Saving models ...\n",
      "epoch: 55, train loss: 0.046\n",
      "Saving models ...\n",
      "epoch: 56, train loss: 0.046\n",
      "Saving models ...\n",
      "epoch: 57, train loss: 0.045\n",
      "Saving models ...\n",
      "epoch: 58, train loss: 0.045\n",
      "Saving models ...\n",
      "epoch: 59, train loss: 0.045\n",
      "Saving models ...\n",
      "epoch: 60, train loss: 0.045\n",
      "Saving models ...\n",
      "epoch: 61, train loss: 0.044\n",
      "Saving models ...\n",
      "epoch: 62, train loss: 0.044\n",
      "Saving models ...\n",
      "epoch: 63, train loss: 0.044\n",
      "Saving models ...\n",
      "epoch: 64, train loss: 0.044\n",
      "Saving models ...\n",
      "epoch: 65, train loss: 0.043\n",
      "Saving models ...\n",
      "epoch: 66, train loss: 0.043\n",
      "Saving models ...\n",
      "epoch: 67, train loss: 0.043\n",
      "Saving models ...\n",
      "epoch: 68, train loss: 0.043\n",
      "Saving models ...\n",
      "epoch: 69, train loss: 0.042\n",
      "Saving models ...\n",
      "epoch: 70, train loss: 0.042\n",
      "Saving models ...\n",
      "epoch: 71, train loss: 0.042\n",
      "Saving models ...\n",
      "epoch: 72, train loss: 0.042\n",
      "Saving models ...\n",
      "epoch: 73, train loss: 0.041\n",
      "Saving models ...\n",
      "epoch: 74, train loss: 0.041\n",
      "Saving models ...\n",
      "epoch: 75, train loss: 0.041\n",
      "Saving models ...\n",
      "epoch: 76, train loss: 0.041\n",
      "Saving models ...\n",
      "epoch: 77, train loss: 0.041\n",
      "Saving models ...\n",
      "epoch: 78, train loss: 0.040\n",
      "Saving models ...\n",
      "epoch: 79, train loss: 0.040\n",
      "Saving models ...\n",
      "epoch: 80, train loss: 0.040\n",
      "Saving models ...\n",
      "epoch: 81, train loss: 0.040\n",
      "Saving models ...\n",
      "epoch: 82, train loss: 0.040\n",
      "Saving models ...\n",
      "epoch: 83, train loss: 0.040\n",
      "Saving models ...\n",
      "epoch: 84, train loss: 0.039\n",
      "Saving models ...\n",
      "epoch: 85, train loss: 0.039\n",
      "Saving models ...\n",
      "epoch: 86, train loss: 0.039\n",
      "Saving models ...\n",
      "epoch: 87, train loss: 0.039\n",
      "Saving models ...\n",
      "epoch: 88, train loss: 0.039\n",
      "Saving models ...\n",
      "epoch: 89, train loss: 0.039\n",
      "Saving models ...\n",
      "epoch: 90, train loss: 0.039\n",
      "Saving models ...\n",
      "epoch: 91, train loss: 0.038\n",
      "Saving models ...\n",
      "epoch: 92, train loss: 0.038\n",
      "Saving models ...\n",
      "epoch: 93, train loss: 0.038\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 94, train loss: 0.038\n",
      "Saving models ...\n",
      "epoch: 95, train loss: 0.038\n",
      "Saving models ...\n",
      "epoch: 96, train loss: 0.038\n",
      "Saving models ...\n",
      "epoch: 97, train loss: 0.038\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 98, train loss: 0.038\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 99, train loss: 0.038\n",
      "Saving models ...\n",
      "epoch: 100, train loss: 0.037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regression_data = {\n",
    "    \"wine\": (wine_train, wine_test),\n",
    "    \"housing\": (housing_train, housing_test),\n",
    "    \"autompg\": (autompg_train, autompg_test)\n",
    "}\n",
    "regressors = []\n",
    "\n",
    "for dataset in regression_data.keys():\n",
    "    train_data, test_data = regression_data[dataset]\n",
    "    base_regressor = BaseRegressor(\n",
    "        input_dim=train_data.features.shape[1], output_dim=1, n_hidden_layers=4, layer_size=128).to(device)\n",
    "    surrogate_regressor = SurrogateRegressor(input_dim=train_data.features.shape[1], output_dim=1).to(device)\n",
    "    print(f\"{dataset}:\")\n",
    "    early_stopping = EarlyStopping(dir=save_dir, dataset_name=dataset, patience=patience, verbose=False)\n",
    "    train(base_regressor, surrogate_regressor, train_data, regression_criterion, epochs, alpha, early_stopping)\n",
    "    regressors.append((base_regressor, surrogate_regressor))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine:\n",
      "test mse: 0.415\n",
      "global fidelity: 0.042, global neighborhood fidelity: 0.041\n",
      "\n",
      "housing:\n",
      "test mse: 0.256\n",
      "global fidelity: 0.022, global neighborhood fidelity: 0.027\n",
      "\n",
      "autompg:\n",
      "test mse: 0.118\n",
      "global fidelity: 0.022, global neighborhood fidelity: 0.022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, dataset in enumerate(regression_data.keys()):\n",
    "    test_data = regression_data[dataset][1]\n",
    "    \n",
    "    base_model = BaseRegressor(\n",
    "        input_dim=test_data.features.shape[1], output_dim=1, n_hidden_layers=4, layer_size=128).to(device)\n",
    "    surrogate_model = SurrogateRegressor(input_dim=test_data.features.shape[1], output_dim=1).to(device)\n",
    "    \n",
    "    base_model.load_state_dict(torch.load(f\"{save_dir}/{dataset}/base_model_checkpoint.pt\"))\n",
    "    surrogate_model.load_state_dict(torch.load(f\"{save_dir}/{dataset}/surrogate_model_checkpoint.pt\"))\n",
    "    \n",
    "    base_model.eval()\n",
    "    surrogate_model.eval()\n",
    "    \n",
    "    print(f\"{dataset}:\")\n",
    "    validate_regressors(base_model, surrogate_model, test_data)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
